p8105\_hw3\_smm2350
================
Shaina Mackin
2021-10-20

# Homework 3

To begin, I will load the necessary packages and instacart data and set
theme options.

## Problem 1

### Instacart data

I will write a short description of the dataset, noting the size and
structure of the data, describing key variables, and giving illustrative
examples of observations:

The instacart dataset contains online grocery shopping data from 2017,
with 1384617 observations, or products from orders, and 15 variables,
for a total of 20769255 data points. Key variables include `order_id`,
`product_id`, `user_id`, whether items were `reordered`,
`order_hour_of_day` and `days_since_prior_order` (ranging from 0 to 30
), as well as `product_name` and associated `aisle` and `department`.

Initial analysis shows `produce` to be the most frequently ordered from
department, as visualized below:

``` r
instacart %>%
  count(department) %>%
  arrange(desc(n)) %>%
  ggplot(aes(forcats::fct_reorder(department, (n)), n)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Departments in decreasing order of popularity",
    x = "Department name",
    y = "Number of items ordered",
  )
```

![](p8105_hw3_smm2350_files/figure-gfm/exploration-1.png)<!-- -->

#### Let’s explore how many aisles are there, and which aisles are the most ordered from.

``` r
instacart %>%
  group_by(aisle_id, aisle) %>%
  summarize(n_obs = n()) %>%
  arrange(desc(n_obs)) 
```

    ## `summarise()` has grouped output by 'aisle_id'. You can override using the `.groups` argument.

    ## # A tibble: 134 × 3
    ## # Groups:   aisle_id [134]
    ##    aisle_id aisle                          n_obs
    ##       <int> <chr>                          <int>
    ##  1       83 fresh vegetables              150609
    ##  2       24 fresh fruits                  150473
    ##  3      123 packaged vegetables fruits     78493
    ##  4      120 yogurt                         55240
    ##  5       21 packaged cheese                41699
    ##  6      115 water seltzer sparkling water  36617
    ##  7       84 milk                           32644
    ##  8      107 chips pretzels                 31269
    ##  9       91 soy lactosefree                26240
    ## 10      112 bread                          23635
    ## # … with 124 more rows

There are 134 aisles. The aisles with the most ordered from items are
`fresh vegetables` and `fresh fruits`, followed by
`packaged vegetables fruits`.

#### To illustrate this, I will make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered.

``` r
instacart %>%
  count(aisle) %>%
  filter(n > 10000) %>%
  ggplot(aes(forcats::fct_reorder(aisle, (n)), n)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Number of items ordered per aisle",
    x = "Aisle name",
    y = "Number of items",
    caption = "note: limited to aisles with more than 10,000 items ordered"
  )
```

![](p8105_hw3_smm2350_files/figure-gfm/aisles_plot-1.png)<!-- -->

This again shows that the aisles most ordered from are
`fresh vegetables` and `fresh fruits`, followed by
`packaged vegetables fruits`.

#### I will make a table showing the three most popular items in the `baking ingredients`, `dog food care`, and `packaged vegetables fruits` aisles.

``` r
instacart %>%
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>%
 count(aisle, product_name) %>%
  arrange(desc(n)) %>%
  group_by(aisle) %>%
  slice(1:3) %>%
  arrange(desc(n)) %>%
  group_by(aisle) %>%
  knitr::kable(caption = "Top  3  Items Per Aisle")
```

| aisle                      | product\_name                                 |    n |
|:---------------------------|:----------------------------------------------|-----:|
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |
| baking ingredients         | Light Brown Sugar                             |  499 |
| baking ingredients         | Pure Baking Soda                              |  387 |
| baking ingredients         | Cane Sugar                                    |  336 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |
| dog food care              | Small Dog Biscuits                            |   26 |

Top 3 Items Per Aisle

We see that `organic baby spinach`, `organic raspberries`, and
`organic blueberries` are the top three ordered items from the
`packaged vegetables fruits` aisle; `light brown sugar`,
`pure baking soda`, and `cane sugar` are the top three ordered items
from the `baking ingredients` aisle; and
`snack sticks chicken & rice recipe dog treats`,
`organix chicken & brown rice recipe`, and `small dog biscuits` are the
top three ordered items from the `dog food care` aisle, respectively.

#### I will make a 2x7 table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

``` r
instacart %>%
  mutate(t_day_number = order_dow +1) %>%
  mutate(day_of_week = wday(t_day_number, label = TRUE)) %>%
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>%
  group_by(product_name, day_of_week) %>%
  summarize(mean_hour = round(mean(order_hour_of_day), digits = 2)) %>%
  pivot_wider(
    names_from = day_of_week,
    values_from = mean_hour
  ) %>%
  knitr::kable(caption = "Mean Hour of Day Ordered")
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the `.groups` argument.

| product\_name    |   Sun |   Mon |   Tue |   Wed |   Thu |   Fri |   Sat |
|:-----------------|------:|------:|------:|------:|------:|------:|------:|
| Coffee Ice Cream | 13.77 | 14.32 | 15.38 | 15.32 | 15.22 | 12.26 | 13.83 |
| Pink Lady Apples | 13.44 | 11.36 | 11.70 | 14.25 | 11.55 | 12.78 | 11.94 |

Mean Hour of Day Ordered

`Coffee Ice Cream` is ordered, on average, later in the day than
`Pink Lady Apples`.

## Problem 2

### BRFSS data

I will clean the data, formatting to use appropriate variable names,
focusing on the `Overall Health` topic, and only including factored
responses ordered from `Excellent` to `Poor`.

``` r
data("brfss_smart2010")

brfss_tidy = brfss_smart2010 %>%
  janitor::clean_names() %>%
   filter(
    topic %in% "Overall Health",
    response %in% "Poor" | response %in% "Fair" | response %in% "Good" | response %in% "Very good" | response %in% "Excellent") %>% 
 mutate(response_ordered = factor(response, ordered = TRUE, levels = c("Poor", "Fair", "Good", "Very good", "Excellent")))
```

#### Let’s determine which states were observed at 7 or more locations in 2002 and 2010.

``` r
brfss_tidy %>%
  select(year, locationabbr, locationdesc) %>%
  filter(year == 2002) %>%
  distinct() %>%
  group_by(locationabbr) %>%
  filter(n() >= 7) %>%
  select(locationabbr) %>%
  distinct()
```

    ## # A tibble: 6 × 1
    ## # Groups:   locationabbr [6]
    ##   locationabbr
    ##   <chr>       
    ## 1 CT          
    ## 2 FL          
    ## 3 MA          
    ## 4 NJ          
    ## 5 NC          
    ## 6 PA

``` r
brfss_tidy %>%
  select(year, locationabbr, locationdesc) %>%
  filter(year == 2010) %>%
  distinct() %>%
  group_by(locationabbr) %>%
  filter(n() >= 7) %>% 
  select(locationabbr) %>%
  distinct() 
```

    ## # A tibble: 14 × 1
    ## # Groups:   locationabbr [14]
    ##    locationabbr
    ##    <chr>       
    ##  1 CA          
    ##  2 CO          
    ##  3 FL          
    ##  4 MD          
    ##  5 MA          
    ##  6 NE          
    ##  7 NJ          
    ##  8 NY          
    ##  9 NC          
    ## 10 OH          
    ## 11 PA          
    ## 12 SC          
    ## 13 TX          
    ## 14 WA

In 2002, `CT`, `FL`, `MA`, `NJ`, `NC`, and `PA` were observed at 7 or
more locations. In 2010, `CA`, `CO`, `FL`, `MD`, `MA`, `NE`, `NJ`, `NY`,
`NC`, `OH`, `PA`, `SC`, `TX`, and `WA` were observed at 7 or more
locations.

#### I will construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data\_value across locations within a state. I will also make a “spaghetti” plot of this average value over time within a state.

``` r
df_excellent = brfss_tidy %>%
  filter(response %in% "Excellent") %>%
  select(year, locationabbr, data_value) %>%
  unique() %>%
  na.omit() %>%
  group_by(locationabbr, year) %>%
  mutate(
    avg_data_value = mean(data_value)) %>%
  select(year, locationabbr, avg_data_value) %>%
  distinct()

df_excellent %>%
  ggplot(aes(x = year, y = avg_data_value)) +
  geom_line(aes(group = locationabbr, color = locationabbr)) +
  labs(
    title = "Average data value among states over time",
    x = "Year",
    y = "Average Data Value") +
  guides(col=guide_legend("State")) +
  theme(legend.position = "right")
```

![](p8105_hw3_smm2350_files/figure-gfm/brfss_excellent-1.png)<!-- -->

The state with the lowest average data value over the years, across
locations, is `WY`.

#### I will make a two-panel plot showing, for the years 2006, and 2010, distribution of data\_value for responses (“Poor” to “Excellent”) among locations in NY State.

``` r
brfss_tidy %>%
  select(year, data_value, locationabbr, locationdesc, response_ordered) %>%
  filter(
    year == 2006 | year == 2010,
    locationabbr == "NY") %>%
  ggplot(aes(x = data_value, fill = response_ordered)) +
  geom_density(aes(fill = response_ordered), alpha = .5) + 
  labs(
    title = "Data value across responses among NY locations",
    x = "Data Value",
    fill = "Response"
  ) +
  theme(
    axis.title.y = element_blank(),
    axis.text.y = element_blank()) +
  facet_grid(. ~ year) +
   guides(col=guide_legend("Location"))
```

![](p8105_hw3_smm2350_files/figure-gfm/brfss_excellent_plot-1.png)<!-- -->

For both `2006` and `2010`, the highest `data_value` among all NY
locations was associated with a `Good` `response`.

## Problem 3

### Accelerometer data

First, I will load and tidy the accelerometer data.

``` r
accel_df = read_csv("accel_data.csv") %>%
  janitor::clean_names() %>%
  mutate(
    day = factor(day, ordered = TRUE,
                 levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")),
    week = factor(week, ordered = TRUE,
                  levels = c(1:5)),
    weekend_or_weekday = ifelse(day %in% c("Saturday", "Sunday"), "weekend", "weekday") %>%
    factor(levels = c("weekday", "weekend"))) %>%
    pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "count")
```

    ## Rows: 35 Columns: 1443

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The tidied `accel_df` contains 50400 rows (or observations), one for
every `minute` of every `day` from the 5 `week` period of accelerometer
data collection. The dataset’s 6 variables include the following: week,
day\_id, day, weekend\_or\_weekday, minute, count.

#### Daily activity

I will aggregate across minutes to create a total activity variable for
each day, and create a table showing these totals.

TRENDS?

#### 24-hour plot

I will make a single-panel plot that shows the 24-hour activity time
courses for each day and use color to indicate day of the week.

DESCRIBE!
